{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a8b7e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, f1_score, confusion_matrix, accuracy_score, matthews_corrcoef, accuracy_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075cf337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data\n",
    "data = pd.read_csv('PrOCTOR_sample_data_all.csv', header=0)\n",
    "data1 = data.fillna(data.mean()['MolecularWeight':'Salivary Gland'])\n",
    "data1[\"target\"] = np.where(data1.iloc[:, 1] == \"passed\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b2fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# x, y variable\n",
    "X = data1.iloc[:, 2:-1]\n",
    "y = data1['target']\n",
    "#print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f8f056a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.array(y)\n",
    "y_1 = y.reshape(y.shape[0],-1)\n",
    "#y = scaler.fit_transform(X)\n",
    "des=X[:,:13]\n",
    "body=X[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "061b4eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, KFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 모델설정\n",
    "sm = SMOTE(random_state=202004)\n",
    "loo = LeaveOneOut()\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 111)\n",
    "kfold.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3820b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_change(predict):\n",
    "    y_predict = []\n",
    "    for i in range(len(predict)):\n",
    "        y_predict = np.append(y_predict, predict[i])\n",
    "    \n",
    "    y_predict = np.array(y_predict)\n",
    "    y_predict = y_predict.reshape(y_predict.shape[0],-1)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6a09a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_x = dict()\n",
    "dict_y = dict()\n",
    "\n",
    "class train_model:\n",
    "    def __init__(self, x, y, pd_des, pd_body):\n",
    "        self.X = x\n",
    "        self.y = y\n",
    "        self.pd_des = pd_des\n",
    "        self.pd_body = pd_body\n",
    "\n",
    "        \n",
    "    def train_based(self):\n",
    "        for train_index, test_index in kfold.split(self.X):\n",
    "            print(\"TEST:\", test_index)\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            svm = SVC(kernel = 'poly' , C = 10.0 , gamma = 0.1)#, class_weight = weight\n",
    "            svm.fit(X_train ,y_train)\n",
    "            pred_y = svm.predict(X_test)\n",
    "   \n",
    "            print(pred_y)\n",
    "\n",
    "            for i in range(len(test_index)):\n",
    "                index = test_index[i]\n",
    "                self.pd_des[index] = pred_y[i]\n",
    "\n",
    "        return self.pd_des\n",
    "    '''\n",
    "    def train_smote(self):\n",
    "        for train_index, test_index in kfold.split(self.X):\n",
    "            print(\"TEST:\", test_index)\n",
    "            des_train, des_test = des[train_index], des[test_index]\n",
    "            body_train, body_test = body[train_index], body[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            sm_des_train, sm_y_train = sm.fit_sample(des_train, y_train)\n",
    "            sm_body_train, _ = sm.fit_sample(body_train, y_train)\n",
    "\n",
    "            self.model.compile(optimizer= keras.optimizers.Adam(), loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "            kf_history = self.model.fit(x = [sm_des_train, sm_body_train], y = sm_y_train, epochs=50)\n",
    "\n",
    "            y_pred = self.model.predict([des_test[:], body_test[:]])\n",
    "            \n",
    "            for i in range(len(test_index)):\n",
    "                index = test_index[i]\n",
    "                self.pd_sm_y[index] = y_pred[i]\n",
    "            \n",
    "        return self.pd_sm_y\n",
    "    '''\n",
    "    def train_weight(self):\n",
    "        for train_index, test_index in kfold.split(self.X):\n",
    "            print(\"TEST:\", test_index)\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "                        \n",
    "            neg, pos = np.bincount(y_train)\n",
    "            total = neg + pos\n",
    "\n",
    "            weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "            weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "            class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "            \n",
    "            svm = SVC(kernel = 'poly' , C = 10.0 , gamma = 0.1, class_weight = weight)#, class_weight = weight\n",
    "            svm.fit(X_train ,y_train)\n",
    "            pred_des = svm.predict(X_test)\n",
    "\n",
    "            pred_des = pred_des[:,1]\n",
    "            \n",
    "            print(pred_des)\n",
    "\n",
    "            for i in range(len(test_index)):\n",
    "                index = test_index[i]\n",
    "                self.pd_des[index] = pred_des[i]\n",
    "\n",
    "        return self.pd_des\n",
    "\n",
    "    def train_sm_weight(self):\n",
    "        for train_index, test_index in kfold.split(self.X):\n",
    "            print(\"TEST:\", test_index)\n",
    "            X_train, X_test = self.X[train_index], self.X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "                        \n",
    "            neg, pos = np.bincount(y_train)\n",
    "            total = neg + pos\n",
    "\n",
    "            weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "            weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "            class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "            \n",
    "            sm_X_train, sm_y_train = sm.fit_resample(X_train, y_train)\n",
    "            \n",
    "            svm = SVC(kernel = 'poly' , C = 10.0 , gamma = 0.1, class_weight = weight)#, class_weight = weight\n",
    "            svm.fit(sm_X_train ,sm_y_train)\n",
    "            pred_des = svm.predict(X_test)\n",
    "\n",
    "\n",
    "            pred_des = rf_des.predict_proba(X_test)\n",
    "\n",
    "            pred_des = pred_des[:,1]\n",
    "            print(pred_des)\n",
    "\n",
    "            for i in range(len(test_index)):\n",
    "                index = test_index[i]\n",
    "                self.pd_des[index] = pred_des[i]\n",
    "\n",
    "\n",
    "        return self.pd_des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f33eb9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc, f1_score, confusion_matrix, accuracy_score, matthews_corrcoef, accuracy_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "import math\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, pred, y):\n",
    "        self.y_pred = pred\n",
    "        self.y = y\n",
    "        \n",
    "    def matrix(self):\n",
    "        y_1 = self.y.reshape(self.y.shape[0],-1)\n",
    "        y_pred = np.array(self.y_pred)\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0], -1)\n",
    "        \n",
    "        y_classify = []\n",
    "        for i in range(len(self.y_pred)):\n",
    "            if self.y_pred[i] >= 0.5:\n",
    "                a = 1.\n",
    "                y_classify.append(a)\n",
    "            else:\n",
    "                a = 0.\n",
    "                y_classify.append(a)\n",
    "        \n",
    "        fpr,tpr,threshold = roc_curve(y_1 , y_pred, pos_label = 1)\n",
    "        precision, recall, threshold = precision_recall_curve(y_1, y_pred, pos_label = 1)\n",
    "        \n",
    "        roc_auc = auc(fpr,tpr)\n",
    "        auprc = auc(recall, precision)\n",
    "        mean_precision = np.mean(precision)\n",
    "        mean_recall = np.mean(recall)\n",
    "        F1 = 2 * (mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
    "        # binary \n",
    "        accuracy = accuracy_score(y_1, y_classify)\n",
    "        mcc = matthews_corrcoef(y_1, y_classify) \n",
    "        g_mean = geometric_mean_score(y_1, y_classify)\n",
    "        confusion = confusion_matrix(y_1, y_classify)\n",
    "        print(confusion.ravel())\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        tpr = tp / (tp + fn)\n",
    "        tnr = tn / (tn + fp)\n",
    "        ppv = tp / (tp + fp)\n",
    "        fnr = fn / (fn + tp)\n",
    "        fpr = fp / (fp + tn)\n",
    "\n",
    "        confu_precision = ppv \n",
    "        confu_recall = tpr # sensitivity\n",
    "        confu_f1 = 2 * ((ppv * tpr) / (ppv + tpr))\n",
    "        confu_accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "        confu_mcc = ((tp * tn)-(fp-fn))/ math.sqrt((tp + fp)*(tp + fn)*(tn + fp)*(tn + fn))\n",
    "        confu_g_mean = math.sqrt(tpr * tnr)\n",
    "        Optimized_precision = (confu_accuracy - abs(tnr-tpr)) / (tnr + tpr)\n",
    "\n",
    "        print('공통 \\nAUC :',roc_auc) # pb\n",
    "        print(\"AUPRC :\", auprc) # pb\n",
    "        print(\"Optimized precision :\", Optimized_precision)\n",
    "\n",
    "        print(\"\\nfunction 사용\\nAccuracy :\", accuracy) #pb\n",
    "        print(\"Precision(pb) :\",mean_precision )\n",
    "        print(\"Recall(pb) :\", mean_recall) # pb\n",
    "        print(\"F1 score(pb) :\", F1) #pb\n",
    "\n",
    "        print(\"MCC :\", mcc)\n",
    "        print(\"G-mean :\", g_mean)\n",
    "\n",
    "\n",
    "        print(\"\\nConfusion_matrix 사용 \\n\", confusion)\n",
    "        print(\"Accuracy :\", confu_accuracy)\n",
    "        print(\"Precision :\", confu_precision) \n",
    "        print(\"Recall :\", confu_recall) \n",
    "        print(\"F1 score :\", confu_f1) \n",
    "\n",
    "        print(\"MCC :\", confu_mcc)\n",
    "        print(\"G-mean :\", confu_g_mean)\n",
    "        \n",
    "        return roc_auc, auprc, Optimized_precision, accuracy, mean_precision, mean_recall, F1, mcc, g_mean, confu_accuracy, confu_precision, confu_recall, confu_f1, confu_mcc, confu_g_mean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af26dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: [  1  11  12  34  36  49  56  71  93 112 119 125 126 140 145 152 157 183\n",
      " 190 194 198 205 209 210 211 214 233 237 257 264 272 298 303 323 328 340\n",
      " 354 368 373 380 399 403 409 412 422 432 434 447 456 461 464 468 474 476\n",
      " 491 496 506 518 520 523 528 532 538 547 553 556 589 611 624 629 645 658\n",
      " 665 700 702 708 735 757 766 774 799 800 825]\n",
      "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 0 1 1 1 1 1]\n",
      "TEST: [  5  39  46  52  68 102 104 122 162 164 166 167 223 228 230 234 249 258\n",
      " 277 280 281 291 326 331 332 338 342 366 374 375 381 383 389 401 413 421\n",
      " 423 431 443 444 460 465 471 481 493 498 507 516 526 537 551 572 575 581\n",
      " 586 604 606 613 632 651 652 653 664 666 673 694 701 706 707 709 718 723\n",
      " 744 745 754 767 769 780 783 789 806 816 822]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 0 0 1 1]\n",
      "TEST: [ 13  16  22  23  24  43  59  72  87  94  96 100 132 134 146 150 158 175\n",
      " 180 189 192 195 240 241 243 246 262 263 271 279 301 307 309 310 325 349\n",
      " 355 360 367 371 395 405 406 436 452 463 469 473 492 499 510 512 530 535\n",
      " 536 549 561 567 577 585 599 601 602 612 618 623 625 627 630 639 648 660\n",
      " 697 719 725 749 753 758 761 768 786 787 797]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 0]\n",
      "TEST: [  0   3  10  20  25  26  32  65  67  73  83  89  97 117 120 121 196 212\n",
      " 215 226 244 248 251 255 261 294 295 314 316 327 335 361 385 386 410 411\n",
      " 415 419 433 440 446 458 462 502 509 514 540 550 582 587 597 600 626 634\n",
      " 644 649 656 663 678 679 684 695 715 717 721 722 729 752 765 785 790 792\n",
      " 793 795 796 801 802 804 809 811 814 817 820]\n",
      "[1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1]\n",
      "TEST: [  6  15  18  19  27  30  57  63  76  99 106 107 115 130 143 147 169 182\n",
      " 184 185 186 188 199 204 208 218 221 224 225 227 238 256 269 278 285 306\n",
      " 319 320 321 336 337 339 341 347 351 353 358 402 407 408 414 425 438 439\n",
      " 442 450 459 484 489 495 517 559 564 565 576 584 594 621 655 668 671 674\n",
      " 676 688 691 696 720 734 746 750 763 798 807]\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0\n",
      " 1 1 0 0 1 0 1 1 1]\n",
      "TEST: [  2   9  53  58  77  85 101 111 131 133 149 153 154 165 172 176 193 201\n",
      " 202 242 250 252 282 300 308 311 312 318 329 330 346 357 359 370 384 388\n",
      " 397 416 420 441 451 467 472 487 497 503 524 527 534 552 554 557 558 573\n",
      " 579 583 593 596 605 614 633 637 642 654 659 661 672 682 687 711 730 736\n",
      " 741 751 755 756 760 777 784 812 813 823 826]\n",
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "TEST: [  4  17  29  38  45  47  48  61  92  95 109 114 116 124 142 151 168 171\n",
      " 179 181 203 206 207 213 216 217 247 253 254 259 267 274 276 286 287 299\n",
      " 305 315 333 352 362 365 369 376 382 392 404 424 427 448 457 480 494 500\n",
      " 504 522 533 541 544 568 569 588 603 608 620 638 640 657 667 670 677 686\n",
      " 690 716 726 737 748 759 776 779 781 803 827]\n",
      "[1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 0]\n",
      "TEST: [ 14  28  35  41  44  51  55  78  81  88  90 108 127 128 148 155 159 161\n",
      " 163 174 191 220 229 235 245 265 288 292 297 313 343 348 372 387 390 393\n",
      " 394 398 400 417 430 435 445 453 454 478 479 482 501 515 521 529 531 542\n",
      " 545 555 574 578 592 595 607 610 616 619 622 628 635 636 647 650 675 692\n",
      " 693 703 705 710 739 762 772 788 791 815 821]\n",
      "[1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1]\n",
      "TEST: [  8  31  33  40  42  60  66  70  79  80  82  84  98 103 105 110 113 129\n",
      " 136 138 141 144 156 177 178 197 219 232 239 283 290 293 302 304 317 345\n",
      " 356 363 364 377 378 391 428 437 466 475 486 488 490 505 508 519 539 546\n",
      " 548 560 563 570 580 591 598 631 641 662 680 699 704 713 727 733 764 770\n",
      " 771 773 775 778 782 794 805 810 818 824]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1]\n",
      "TEST: [  7  21  37  50  54  62  64  69  74  75  86  91 118 123 135 137 139 160\n",
      " 170 173 187 200 222 231 236 260 266 268 270 273 275 284 289 296 322 324\n",
      " 334 344 350 379 396 418 426 429 449 455 470 477 483 485 511 513 525 543\n",
      " 562 566 571 590 609 615 617 643 646 669 681 683 685 689 698 712 714 724\n",
      " 728 731 732 738 740 742 743 747 808 819]\n",
      "[1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "svm_y, svm_sm_y, svm_cw_y, svm_smcw_y = [], [], [], []\n",
    "output_svm = train_model(X, y, dict_x, dict_y)\n",
    "svm_y = output_rf.train_based()\n",
    "final_result = Evaluation(predict_change(svm_y), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d8822df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 15  56  81 676]\n",
      "공통 \n",
      "AUC : 0.55213314231492\n",
      "AUPRC : 0.9571610168560608\n",
      "Optimized precision : 0.13838146791824\n",
      "\n",
      "function 사용\n",
      "Accuracy : 0.8345410628019324\n",
      "Precision(pb) : 0.9459161584963439\n",
      "Recall(pb) : 0.6309995596653457\n",
      "F1 score(pb) : 0.7570127846621257\n",
      "MCC : 0.09118635489299168\n",
      "G-mean : 0.4343520378053286\n",
      "\n",
      "Confusion_matrix 사용 \n",
      " [[ 15  56]\n",
      " [ 81 676]]\n",
      "Accuracy : 0.8345410628019324\n",
      "Precision : 0.9234972677595629\n",
      "Recall : 0.892998678996037\n",
      "F1 score : 0.9079919408999328\n",
      "MCC : 0.16540137357017495\n",
      "G-mean : 0.4343520378053286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.55213314231492,\n",
       " 0.9571610168560608,\n",
       " 0.13838146791824,\n",
       " 0.8345410628019324,\n",
       " 0.9459161584963439,\n",
       " 0.6309995596653457,\n",
       " 0.7570127846621257,\n",
       " 0.09118635489299168,\n",
       " 0.4343520378053286,\n",
       " 0.8345410628019324,\n",
       " 0.9234972677595629,\n",
       " 0.892998678996037,\n",
       " 0.9079919408999328,\n",
       " 0.16540137357017495,\n",
       " 0.4343520378053286)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.matrix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
